{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flavors of Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent (GD) is a tremendously popular optimization algorithm in the machine learning world. While it's been popular for a long time, there have been a number of variations on plain-vanilla SGD that have improved training speed and stability. The four we'll cover in this post are:\n",
    "* Basic gradient descent\n",
    "* Momentum\n",
    "* RMSProp\n",
    "* Adam\n",
    "\n",
    "First, a brief review. GD's purpose is simple: given a function, change the parameters of that function to find its minimum. One of the major \"families\" of (supervised) machine learning models is the set of *parametric* models, or those which work by tuning a set of _parameters_ (hence the name!) to optimize some objective criterion. In each case, we have a function that takes a series of samples, and for each, tries to predict a target; that is:\n",
    "\n",
    "$$\n",
    "\\operatorname*{argmin}_fL(y,f(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $f$ is a parametric supervised learning model, $y$ is a vector of ground-truth values, $x$ is a feature matrix $\\in R^{mn}$ and $f$ is a function $R^{m*n} \\Rightarrow R^{1*n}$; for simplicity, let's assume it's a basic linear regression, such as $f(x) = \\beta_{0} + \\beta_{1}x$. In this case, we want to find the parameters $\\beta_0$ and $\\beta_1$ that minimize the average _loss_ (function $l$ above) given a set of examples $y$ and a set of inputs $x$. For example's sake, let's assume that loss to be _Mean Squared Error (MSE)_: $\\frac{1}{n}\\sum^n_1(y_i - f(x_i))^2$. Gradient descent helps us find the parameters $\\beta_0$ and $\\beta_1$ that make the MSE as small as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is this done? The broad idea is straightforward: figure out how the loss moves in relation to each parmeter, and use that information to determine whether to increase or decrease the parameter. Repeat the process many times, until the loss won't go any lower. Each \"flavor\" of GD outlined above does this in some form, but the nuances of the approach differ. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by generating a bit of data on which we can run our GS algorithm to examine training performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import normal\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Some Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's pick some constants to be our \"true\" $\\beta_0$ and $\\beta_1$. Remember: our goal is to take some data generated by a linear model with these parameters, and use it to back into what the parameters were algorithmically. We'll set $\\beta_1 = 30$ and $\\beta_0 = 15$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b1, b0 = 30, 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to generated some input and output data. This will be our synthetic training data, which we'll use to back into the parameters we set above. Our data will be centered around the line $y = 30x + 15$, with a small amount of normally distributed noise added, with a mean of 0 and standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.linspace(0, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = b1 * x_train + b0 + normal(size=len(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've used scipy's `normal` function to generate random error terms with mean 0 and standard deviation 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc167fd6940>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data clings pretty tightly to our ground-truth function, which is fine for now -- real-world data is almost never so clean, but it'll work for the purposes of this post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first variant we're going to work through is basic SGD. The idea in basic SGD is simple: we find the gradient of the error with respect to the inputs, and then we subtract that gradient (multipled by a small number) to improve the error a bit. More formally:\n",
    "\n",
    "$$ a_{t+1} = a_t - \\alpha\\frac{\\delta{L}}{\\delta{a}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\alpha$ is the learning rate, and $\\frac{\\delta{L}}{\\delta{a}}$ is the gradient of the loss with respect to the parameter $a$. Basic SGD does exactly this, more-or-less, with no modifications. One thing worth noting is that the process changes based on _how many_ examples you use to determine the gradient. Broadly, there are three ways to do this:\n",
    "* Batch gradient descent, which computes the gradient over every example in the training set, and then makes one parameter update per epoch (i.e. for each complete pass through the data)\n",
    "* Mini-batch gradient descent, which breaks the training set into chunks and computes the gradient (and performs parameter updates) for each chunk\n",
    "* Online gradient descent, which computes the gradient and updates the parameters for each individual training example\n",
    "\n",
    "There are advantages and disadvantages to each of these, primarily around training speed and stability. To scope this post down to a reasonable level, I'll save that discussion for a different post. For the purposes of this post, we're going to be using batch gradient descent for each variant of SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE: 3060533.696181104\n",
      "b0_hat is 0.30300950520015735\n",
      "b1_hat is 20.251526299769125\n",
      "Epoch 10000 MSE: 20.45762293523531\n",
      "b0_hat is 6.255557333936195\n",
      "b1_hat is 30.131287842694327\n",
      "Epoch 20000 MSE: 7.984352926739002\n",
      "b0_hat is 9.749650815607396\n",
      "b1_hat is 30.079135864817022\n",
      "Epoch 30000 MSE: 3.4634447455217763\n",
      "b0_hat is 11.853221944350848\n",
      "b1_hat is 30.047738480761605\n",
      "Epoch 40000 MSE: 1.8248519170916848\n",
      "b0_hat is 13.119648133831623\n",
      "b1_hat is 30.02883611568079\n",
      "Best loss:  1.2309819621626716\n"
     ]
    }
   ],
   "source": [
    "# set the epoch count to 50000\n",
    "epochs = 50000\n",
    "\n",
    "# initialize our parameters\n",
    "b0_hat, b1_hat = 0, 0\n",
    "\n",
    "# set the learning rate\n",
    "lr = 1e-4\n",
    "\n",
    "# we'll use this list to collect our losses for reporting\n",
    "basic_losses = []\n",
    "\n",
    "# This is our main optimization loop. For each epoch, we're going to\n",
    "# compute the average gradient over the entire dataset, then use that\n",
    "# average gradient to update the parameters. \n",
    "for i in range(epochs):\n",
    "    \n",
    "    # vectorized prediction for the  basic linear model\n",
    "    predictions = np.dot(b1_hat, x_train) + b0_hat\n",
    "    \n",
    "    # compute the loss for each example\n",
    "    loss = (predictions - y_train)**2\n",
    "    \n",
    "    # log the MSE for the epoch\n",
    "    basic_losses.append(loss.mean())\n",
    "    \n",
    "    # compute the gradients for each parameter\n",
    "    grad_b0 = (2 * (predictions - y_train)).mean()\n",
    "    grad_b1 = (2 * (predictions - y_train) * x_train).mean()\n",
    "    \n",
    "    # update the parameters\n",
    "    b0_hat = b0_hat - grad_b0 * lr\n",
    "    b1_hat = b1_hat - grad_b1 * lr\n",
    "    \n",
    "    # every 10k epochs, print out the loss\n",
    "    if (i % 10000 == 0):\n",
    "        print(\"Epoch %s MSE: %s\" % (i, basic_losses[-1]))\n",
    "        print(\"b0_hat is %s\" % b0_hat)\n",
    "        print(\"b1_hat is %s\" % b1_hat)\n",
    "print(\"Best loss: \", min(basic_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the end of our training loop, you can see that the learned parameters, $\\hat{\\beta}_{0} = 13.12$ and $\\hat{\\beta}_{1} = 30.02$ are pretty close to our true parameters $\\beta_{0} = 15$ and $\\beta_{1} = 30$, so our algorithm is working as we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Basic - PyTorch Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variant, I also wanted to take the time to demonstrate what it would look like in PyTorch, one of the more popular deep learning platforms. We start by creating a PyTorch tensor. `torch.tensor` is a constructor for `torch.Tensor` objects, which work a lot like numpy tensors with extra functionality that allow them to be stored on a GPU. We also add a feature of ones to the dataset to account for $\\beta_{0}$, which can then be optimized with the same gradient calculation as $\\beta_1$ in our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_x_train_torch = np.concatenate((x_train[:,np.newaxis], np.ones((len(x_train)))[:,np.newaxis]), axis=1)\n",
    "x_train_torch = torch.tensor(_x_train_torch).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 2]), torch.Size([2]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_torch.shape, w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.0000],\n",
       "        [1.0101, 1.0000],\n",
       "        [2.0202, 1.0000],\n",
       "        [3.0303, 1.0000],\n",
       "        [4.0404, 1.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_torch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred): return ((y_true - y_pred)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_torch = torch.tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1749.4381087026497\n",
      "4.523010384161774\n",
      "2.8256597330073205\n",
      "1.8610332467534738\n",
      "1.3508707995554885\n",
      "1.1094962650512492\n"
     ]
    }
   ],
   "source": [
    "w = torch.nn.Parameter(torch.tensor([0.,0.]).double())\n",
    "lr = 1e-4\n",
    "basic_losses_torch = []\n",
    "for i in range(50000):\n",
    "    pred = x_train_torch@w\n",
    "    loss = mse(y_train_torch, pred)\n",
    "    basic_losses_torch.append(loss.item())\n",
    "    if i % 10000 == 0: print(np.sqrt(loss.detach().numpy()))\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w.sub_(lr * w.grad)\n",
    "        w.grad.zero_() \n",
    "print(np.sqrt(min(basic_losses_torch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent loss after epoch 0 is 1775.3399029003915\n",
      "a_hat is 20.42608101348564\n",
      "b_hat is 0.3061450025880595\n",
      "The most recent loss after epoch 10000 is 195.46258656134677\n",
      "a_hat is 30.10709685012657\n",
      "b_hat is 25.331253310966208\n",
      "The most recent loss after epoch 20000 is 195.46257127267637\n",
      "a_hat is 30.10482135073294\n",
      "b_hat is 25.483707885508505\n",
      "The most recent loss after epoch 30000 is 195.4625712721069\n",
      "a_hat is 30.104807462954312\n",
      "b_hat is 25.484638342967305\n",
      "The most recent loss after epoch 40000 is 195.46257127210689\n",
      "a_hat is 30.104807378194717\n",
      "b_hat is 25.484644021715106\n",
      "Best loss:  38205.616768303444\n"
     ]
    }
   ],
   "source": [
    "epochs = 50000\n",
    "a_hat, b_hat = 0., 0.\n",
    "lr = 1e-3\n",
    "mom = 0.9\n",
    "mom_losses = []\n",
    "grad_a = 0.0\n",
    "grad_b = 0.0\n",
    "for i in range(epochs):\n",
    "    prediction = np.dot(a_hat, x_train) + b_hat\n",
    "    loss = np.mean((prediction - y_train)**2)\n",
    "    mom_losses.append(loss)\n",
    "    grad_a = np.mean(2 * (prediction - y_train) * x_train) * (1 - mom) + grad_a * mom\n",
    "    grad_b = np.mean(2 * (prediction - y_train)) * (1 - mom) + grad_b * mom\n",
    "    a_hat = a_hat - grad_a * lr\n",
    "    b_hat = b_hat - grad_b * lr\n",
    "    if (i % 10000 == 0):\n",
    "        print(\"The most recent loss after epoch %s is %s\" % (i, np.sqrt(loss)))\n",
    "        print(\"a_hat is %s\" % a_hat)\n",
    "        print(\"b_hat is %s\" % b_hat)\n",
    "print(\"Best loss: \", min(mom_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_list(losses):\n",
    "    return list(map(lambda x: np.mean(x), losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc16c0426a0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIOIOwAYRNwBwCDiDgAGEXcAMOj/APoaXyqRh4EmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "# momentum_losses = losses\n",
    "# ax.set_xlim(0,3000)\n",
    "ax.set_ylim(0,100)\n",
    "plt.plot(loss_list(mom_losses), color=\"blue\")\n",
    "plt.plot(loss_list(basic_losses), color=\"red\")\n",
    "# plot_losses(losses[1:], 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model can handle a learning rate 10x larger, allowing us to learn much more quickly. The SGD-based version could not handle the larger learning rate, and immediately started to diverge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum - PyTorch Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3060265.0966, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(0.9793, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(0.9772, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(0.9772, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(0.9772, dtype=torch.float64, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "w = torch.nn.Parameter(torch.tensor([0.,0.]).double())\n",
    "lr = 1e-3\n",
    "mom = 0.9\n",
    "grad = torch.tensor([0.,0.]).double()\n",
    "mom_torch_losses = []\n",
    "for i in range(50000):\n",
    "    pred = x_train_torch@w\n",
    "    loss = mse(y_train_torch, pred).double()\n",
    "    mom_torch_losses.append(loss)\n",
    "    if i % 10000 == 0: print(loss)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        grad_mom = mom * grad + (1 - mom) * w.grad\n",
    "        w.sub_(lr * grad_mom)\n",
    "        grad = grad_mom\n",
    "        w.grad.zero_() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent after epoch 5000 is 1.0635296202610103\n",
      "a_hat is 30.00158555385953\n",
      "b_hat is 15.196067246693122\n",
      "The most recent after epoch 10000 is 1.0634643388384801\n",
      "a_hat is 30.001824516445303\n",
      "b_hat is 15.180136282584968\n",
      "The most recent after epoch 15000 is 1.0634643388384801\n",
      "a_hat is 30.001824516445303\n",
      "b_hat is 15.180136282584968\n",
      "The most recent after epoch 20000 is 1.0634643388384801\n",
      "a_hat is 30.001824516445303\n",
      "b_hat is 15.180136282584968\n",
      "The most recent after epoch 25000 is 1.0634643388384801\n",
      "a_hat is 30.001824516445303\n",
      "b_hat is 15.180136282584968\n",
      "The most recent after epoch 30000 is 1.0634643388384801\n",
      "a_hat is 30.001824516445303\n",
      "b_hat is 15.180136282584968\n",
      "The most recent after epoch 35000 is 1.0634643388384801\n",
      "a_hat is 30.001824516445303\n",
      "b_hat is 15.180136282584968\n",
      "The most recent after epoch 40000 is 1.0634643388384801\n",
      "a_hat is 30.001824516445303\n",
      "b_hat is 15.180136282584968\n",
      "The most recent after epoch 45000 is 1.0634643388384801\n",
      "a_hat is 30.001824516445303\n",
      "b_hat is 15.180136282584968\n",
      "The most recent after epoch 50000 is 1.0634643388384801\n",
      "a_hat is 30.001824516445303\n",
      "b_hat is 15.180136282584968\n",
      "Best loss:  1.0634643388379823\n"
     ]
    }
   ],
   "source": [
    "epochs = 50000\n",
    "a_hat, b_hat = 0, 0\n",
    "lr = 1e-2\n",
    "beta = 0.9\n",
    "rms_losses = []\n",
    "r_a = 0\n",
    "r_b = 0\n",
    "grad_a = 0\n",
    "grad_b = 0\n",
    "eta = 1e-10\n",
    "for i in range(1, epochs + 1):\n",
    "    predictions = a_hat * x_train + b_hat\n",
    "    loss = ((predictions - y_train)**2).mean()\n",
    "    rms_losses.append(loss)\n",
    "     \n",
    "    grad_a = (2 * (predictions - y_train) * x_train).mean()\n",
    "    grad_b = (2 * (predictions - y_train)).mean()\n",
    "     \n",
    "    r_a = (beta*r_a + (1 - beta)*grad_a**2) / (1 - beta**i)\n",
    "    r_b = (beta*r_b + (1 - beta)*grad_b**2) / (1 - beta**i)\n",
    "     \n",
    "    v_a = grad_a*np.divide(lr, np.sqrt(r_a) + eta)\n",
    "    v_b = grad_b*np.divide(lr, np.sqrt(r_b) + eta)\n",
    "    \n",
    "    a_hat = a_hat - v_a\n",
    "    b_hat = b_hat - v_b\n",
    "    \n",
    "    if (i % 5000 == 0):\n",
    "        print(\"The most recent after epoch %s is %s\" % (i, rms_losses[-1]))\n",
    "        print(\"a_hat is %s\" % a_hat)\n",
    "        print(\"b_hat is %s\" % b_hat)\n",
    "print(\"Best loss: \", min(rms_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f63cb2b0668>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "# momentum_losses = losses\n",
    "ax.set_xlim(0,50000)\n",
    "ax.set_ylim(0,10)\n",
    "plt.plot(loss_list(mom_losses), color=\"blue\")\n",
    "plt.plot(loss_list(basic_losses), color=\"red\")\n",
    "plt.plot(loss_list(rms_losses), color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp - PyTorch Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0635, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(1.0635, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(1.0635, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(1.0635, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(1.0635, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(1.0635, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(1.0635, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(1.0635, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(1.0635, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(1.0635, dtype=torch.float64, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "w = torch.nn.Parameter(torch.tensor([0.,0.]).double())\n",
    "epochs = 50000\n",
    "lr = 1e-2\n",
    "beta = 0.9\n",
    "exp_moving_avg = torch.tensor([0.,0.]).double()\n",
    "eta = 1e-10\n",
    "for i in range(1, epochs + 1):\n",
    "    pred = x_train_torch@w\n",
    "    loss = mse(y_train_torch, pred).double()\n",
    "    if i % 5000 == 0: \n",
    "        print(loss)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        exp_moving_avg = (beta * exp_moving_avg + (1 - beta)*w.grad**2) / (1 - beta**i)\n",
    "        w.sub_(w.grad * lr / (np.sqrt(exp_moving_avg) + eta))\n",
    "        w.grad.zero_() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent after epoch 10000 is 0.9772035034843654\n",
      "a_hat is 29.996685149488872\n",
      "b_hat is 15.17513254882717\n",
      "The most recent after epoch 20000 is 0.9771942517974239\n",
      "a_hat is 29.996947875558817\n",
      "b_hat is 15.175139586707182\n",
      "The most recent after epoch 30000 is 0.9771879445709775\n",
      "a_hat is 29.996718956963324\n",
      "b_hat is 15.17513344936517\n",
      "The most recent after epoch 40000 is 0.9771852044566064\n",
      "a_hat is 29.996910610349904\n",
      "b_hat is 15.175138603995327\n",
      "The most recent after epoch 50000 is 0.9771865094312757\n",
      "a_hat is 29.996759442604894\n",
      "b_hat is 15.175134514468935\n",
      "Best loss:  0.9771851300854203\n"
     ]
    }
   ],
   "source": [
    "epochs = 50000\n",
    "a_hat, b_hat = 0, 0\n",
    "lr = 1e-2\n",
    "\n",
    "beta1 = 0.9\n",
    "beta2 = 0.9\n",
    "\n",
    "adam_losses = []\n",
    "\n",
    "r_a = 0\n",
    "r_b = 0\n",
    "grad_a = 0\n",
    "grad_b = 0\n",
    "mom_a = 0\n",
    "mom_b = 0\n",
    "eta = 10e-1\n",
    "\n",
    "for i in range(1, epochs + 1):\n",
    "    predictions = a_hat * x_train + b_hat\n",
    "    loss = ((predictions - y_train)**2).mean()\n",
    "    adam_losses.append(loss)\n",
    "    \n",
    "    grad_b = (2 * (predictions - y_train)).mean()\n",
    "    grad_a = (2 * (predictions - y_train) * x_train).mean()\n",
    "     \n",
    "    r_a = (beta2*r_a + (1 - beta2)*grad_a**2) / (1 - beta2**i)\n",
    "    r_b = (beta2*r_b + (1 - beta2)*grad_b**2) / (1 - beta2**i)\n",
    "    \n",
    "    mom_a = (grad_a * (1 - beta1) + mom_a * beta1) / (1 - beta1**i)\n",
    "    mom_b = (grad_b * (1 - beta1) + mom_b * beta1) / (1 - beta1**i)\n",
    "\n",
    "    v_a = mom_a * lr / (np.sqrt(r_a) + eta)\n",
    "    v_b = mom_b * lr / (np.sqrt(r_b) + eta)      \n",
    "    \n",
    "    a_hat = a_hat - v_a\n",
    "    b_hat = b_hat - v_b\n",
    "         \n",
    "    if (i % 10000 == 0):\n",
    "        print(\"The most recent after epoch %s is %s\" % (i, adam_losses[-1]))\n",
    "        print(\"a_hat is %s\" % a_hat)\n",
    "        print(\"b_hat is %s\" % b_hat)\n",
    "print(\"Best loss: \", min(adam_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f63cd1c45c0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQiQpCQAhhEhSEgBCCJGk/h9CBpCwZ0PfsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "# momentum_losses = losses\n",
    "ax.set_xlim(0,50000)\n",
    "ax.set_ylim(0,10)\n",
    "plt.plot(loss_list(mom_losses), color=\"blue\")\n",
    "plt.plot(loss_list(basic_losses), color=\"red\")\n",
    "plt.plot(loss_list(rms_losses), color=\"green\")\n",
    "plt.plot(loss_list(adam_losses), color=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam - PyTorch Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3060265.0966, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(0.9773, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(0.9772, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(0.9772, dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
      "tensor(0.9772, dtype=torch.float64, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "w = torch.nn.Parameter(torch.tensor([0.,0.]).double())\n",
    "lr = 1e-2\n",
    "beta1 = 0.9\n",
    "beta2 = 0.9\n",
    "grad = torch.tensor([0.,0.]).double()\n",
    "mom_torch_losses = []\n",
    "eta = 10e-1\n",
    "moving_avg = 0\n",
    "exp_moving_avg = 0\n",
    "for i in range(50000):\n",
    "    pred = x_train_torch@w\n",
    "    loss = mse(y_train_torch, pred).double()\n",
    "    mom_torch_losses.append(loss)\n",
    "    if i % 10000 == 0: print(loss)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        moving_avg = (beta1 * moving_avg + (1 - beta1) * w.grad) / (1 - beta1**(i+1))\n",
    "        exp_moving_avg = (beta2 * exp_moving_avg + (1 - beta2) * w.grad**2) / (1 - beta2**(i+1))\n",
    "        w.sub_(moving_avg * lr / (np.sqrt(exp_moving_avg) + eta))\n",
    "        w.grad.zero_() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
